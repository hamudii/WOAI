{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb83135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a0d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate \\https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\-O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e982c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def parse_data_from_input(dataset_dir):\n",
    "    # Define the path to your dataset directory containing subdirectories for each class\n",
    "\n",
    "    # Initialize empty lists to store images and labels\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Create a list of class labels based on subdirectory names\n",
    "    class_labels = os.listdir(dataset_dir)\n",
    "\n",
    "    # Loop through each subdirectory (class)\n",
    "    for label, class_name in enumerate(class_labels):\n",
    "        class_dir = os.path.join(dataset_dir, class_name)\n",
    "        count = 1 \n",
    "        # Loop through all files in the class directory\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith((\".jpg\", \".png\")):  # Adjust file extensions as needed\n",
    "                new_path = os.path.join(class_dir, filename)\n",
    "                 # Specify the old and new file names\n",
    "                # Generate a unique filename by adding a count to the original filename\n",
    "#                 base_filename, file_extension = os.path.splitext(filename)\n",
    "#                 new_filename = f\"{class_name}_{count}{file_extension}\"\n",
    "#                 new_path = os.path.join(class_dir, new_filename)\n",
    "                \n",
    "                # Increment the count to ensure the next file has a unique name\n",
    "                count += 1\n",
    "\n",
    "                # Rename the file\n",
    "#                 os.rename(file_path, new_path)\n",
    "                # Load the image using OpenCV\n",
    "                image = cv2.imread(new_path)\n",
    "                # If you want to save the grayscale image to a file\n",
    "                cv2.imwrite(new_path, image)\n",
    "\n",
    "                # Resize the image to a consistent size if needed\n",
    "                image = cv2.resize(image, (224, 224))\n",
    "\n",
    "                # Append the image and its corresponding label to the lists\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "\n",
    "    # Convert the lists to NumPy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels\n",
    "\n",
    "    # You can then use 'images' and 'labels' in your machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a617bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_FILE = r'train/'\n",
    "VALIDATION_FILE = r'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9e96e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images has shape: (4682, 224, 224, 3) and dtype: uint8\n",
      "Training labels has shape: (4682,) and dtype: int32\n",
      "Validation images has shape: (355, 224, 224, 3) and dtype: uint8\n",
      "Validation labels has shape: (355,) and dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "# Test your function\n",
    "training_images, training_labels = parse_data_from_input(TRAINING_FILE)\n",
    "validation_images, validation_labels = parse_data_from_input(VALIDATION_FILE)\n",
    "\n",
    "print(f\"Training images has shape: {training_images.shape} and dtype: {training_images.dtype}\")\n",
    "print(f\"Training labels has shape: {training_labels.shape} and dtype: {training_labels.dtype}\")\n",
    "print(f\"Validation images has shape: {validation_images.shape} and dtype: {validation_images.dtype}\")\n",
    "print(f\"Validation labels has shape: {validation_labels.shape} and dtype: {validation_labels.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "379d01ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(training_labels[1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98c3c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "# GRADED FUNCTION: train_val_generators\n",
    "def train_val_generators(training_images, training_labels, validation_images, validation_labels):\n",
    "# def train_val_generators(training_images, training_labels):\n",
    "  train_datagen = ImageDataGenerator(\n",
    "      rescale = 1./255,\n",
    "\t    rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest'\n",
    "      )\n",
    "\n",
    "\n",
    "  # Pass in the appropriate arguments to the flow method\n",
    "#   train_generator = train_datagen.flow(x=training_images,\n",
    "#                                        y=training_labels,\n",
    "#                                        batch_size=126,\n",
    "# )\n",
    "  train_generator = train_datagen.flow_from_directory(\n",
    "\t  TRAINING_FILE,\n",
    "\t  target_size=(224,224),\n",
    "\t  class_mode='categorical',\n",
    "    batch_size=126\n",
    ")\n",
    "  validation_datagen = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "  # Pass in the appropriate arguments to the flow method\n",
    "  # validation_generator = validation_datagen.flow(x=validation_images,\n",
    "  #                                                y=validation_labels,\n",
    "  #                                                batch_size=126)\n",
    "  validation_generator = validation_datagen.flow_from_directory(\n",
    "\t  VALIDATION_FILE,\n",
    "\t  target_size=(224,224),\n",
    "\t  class_mode='categorical',\n",
    "    batch_size=126\n",
    "  )\n",
    "  ### END CODE HERE\n",
    "\n",
    "  return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80681df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4682 images belonging to 4 classes.\n",
      "Found 356 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator = train_val_generators(training_images, training_labels, validation_images, validation_labels)\n",
    "# train_generator = train_val_generators(training_images, training_labels)\n",
    "\n",
    "# print(f\"Images of training generator have shape: {train_generator.x.shape}\")\n",
    "# print(f\"Labels of training generator have shape: {train_generator.y.shape}\")\n",
    "# print(f\"Images of validation generator have shape: {validation_generator.x.shape}\")\n",
    "# print(f\"Labels of validation generator have shape: {validation_generator.y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c68be720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "# from tensorflow.keras.optimizers import RMSprop\n",
    "# inceptionv3 = 'https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "# urllib.request.urlretrieve(inceptionv3, 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "# local_weights_file = 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "# pre_trained_model = InceptionV3(input_shape=(224, 224, 3),include_top=False,weights=None)\n",
    "# pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# for layer in pre_trained_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# last_layer = pre_trained_model.get_layer('mixed7')\n",
    "# last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbd531a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "base_model=MobileNetV2(input_shape=(224,224,3),weights='imagenet',include_top=False) \n",
    "\n",
    "# add Fully-Connected Layers to Model\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(base_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47ddceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            # Check accuracy\n",
    "            if (logs.get('accuracy') > 0.97 and logs.get('val_accuracy') > 0.97):\n",
    "                # Stop if threshold is met\n",
    "                print(\"\\n\\n\\t=====================================\")\n",
    "                print(\"\\t|| accuracy and val_accuracy > 80% ||\")\n",
    "                print(\"\\t=====================================\\n\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d310a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 302s 7s/step - loss: 1.2743 - accuracy: 0.7426 - val_loss: 1.0119 - val_accuracy: 0.9860\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 299s 8s/step - loss: 0.8205 - accuracy: 0.8633 - val_loss: 0.4238 - val_accuracy: 0.9860\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 288s 8s/step - loss: 0.4103 - accuracy: 0.9199 - val_loss: 0.1660 - val_accuracy: 0.9860\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 281s 7s/step - loss: 0.2200 - accuracy: 0.9513 - val_loss: 0.0748 - val_accuracy: 0.9888\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 283s 7s/step - loss: 0.1343 - accuracy: 0.9622 - val_loss: 0.0216 - val_accuracy: 0.9972\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 284s 7s/step - loss: 0.1174 - accuracy: 0.9643 - val_loss: 0.0274 - val_accuracy: 0.9944\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9712\n",
      "\n",
      "\t=====================================\n",
      "\t|| accuracy and val_accuracy > 80% ||\n",
      "\t=====================================\n",
      "\n",
      "38/38 [==============================] - 285s 7s/step - loss: 0.0928 - accuracy: 0.9712 - val_loss: 0.0319 - val_accuracy: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c302d2c790>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(16, activation='relu')(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = RMSprop(learning_rate=0.0001),\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[callbacks]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "418d0fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model():\n",
    "\n",
    "#   ### START CODE HERE\n",
    "\n",
    "#   # Define the model\n",
    "#   # Use no more than 2 Conv2D and 2 MaxPooling2D\n",
    "#   model = tf.keras.models.Sequential([\n",
    "#       tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
    "#       tf.keras.layers.MaxPooling2D(2,2),\n",
    "#       tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "#       tf.keras.layers.MaxPooling2D(2, 2),   \n",
    "#       tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "#       tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#       tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#       tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#       tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#       tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#       tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "#       tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#       # Flatten the results to feed into a DNN\n",
    "#       tf.keras.layers.Flatten(),\n",
    "#       # 512 neuron hidden layer\n",
    "#       tf.keras.layers.Dense(1028, activation='relu'),\n",
    "#       tf.keras.layers.Dense(512, activation='relu'),\n",
    "#       tf.keras.layers.Dense(512, activation='relu'),\n",
    "#       tf.keras.layers.Dense(256, activation='relu'),\n",
    "#       tf.keras.layers.Dense(128, activation='relu'),\n",
    "#       tf.keras.layers.Dense(64, activation='relu'),\n",
    "#       tf.keras.layers.Dense(32, activation='relu'),\n",
    "#       tf.keras.layers.Dense(4, activation='softmax')\n",
    "#   ])\n",
    "\n",
    "\n",
    "#   model.compile(optimizer = 'rmsprop',\n",
    "#                 loss = 'categorical_crossentropy',\n",
    "#                 metrics=['accuracy'])\n",
    "\n",
    "#   ### END CODE HERE\n",
    "\n",
    "#   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d4699a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class myCallback(tf.keras.callbacks.Callback):\n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         if (logs.get('accuracy') > 0.9998 and logs.get('val_accuracy') > 0.9998 and logs.get('loss') < 0.001 and logs.get('val_loss') > 0.001):\n",
    "#             self.model.stop_training = True\n",
    "\n",
    "# calbak = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e6a89ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save your model\n",
    "# model = create_model()\n",
    "\n",
    "# # Train your model\n",
    "# history = model.fit(train_generator,\n",
    "#                     validation_data=validation_generator,\n",
    "#                     epochs=30,\n",
    "#                     verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f2628d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #-----------------------------------------------------------\n",
    "# # Retrieve a list of list results on training and test data\n",
    "# # sets for each training epoch\n",
    "# #-----------------------------------------------------------\n",
    "# acc=model.model['accuracy']\n",
    "# val_acc=model.model['val_accuracy']\n",
    "# loss=model.model['loss']\n",
    "# val_loss=model.model['val_loss']\n",
    "\n",
    "# epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "# #------------------------------------------------\n",
    "# # Plot training and validation accuracy per epoch\n",
    "# #------------------------------------------------\n",
    "# plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "# plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.show()\n",
    "# print(\"\")\n",
    "\n",
    "# #------------------------------------------------\n",
    "# # Plot training and validation loss per epoch\n",
    "# #------------------------------------------------\n",
    "# plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "# plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"15Desember2023-2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f957d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Load the model\n",
    "from keras.models import load_model  # TensorFlow is required for Keras to work\n",
    "import cv2  # Install opencv-python\n",
    "import numpy as np\n",
    "model = load_model(\"15Desember2023.h5\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8712153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Down-Correct\n",
      "[[9.9980479e-01 4.1273775e-05 1.1687775e-04 3.7082104e-05]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## NOTE: If you are using Safari and this cell throws an error,\n",
    "## please skip this block and run the next one instead.\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    " \n",
    "  # predicting images\n",
    "path=r'test\\Down-Correct\\9_59_8_25881_png.rf.c9feedfd7b97964360230b5b58942527.jpg'\n",
    "img=load_img(path, target_size=(224, 224))\n",
    "  \n",
    "x=img_to_array(img)\n",
    "x /= 255\n",
    "x=np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "  \n",
    "classes = model.predict(images, batch_size=16)\n",
    "print(\"Down-Correct\")  \n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c5f848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n",
      "Down-Wrong\n",
      "[[7.0448586e-05 9.9784565e-01 2.4517823e-05 2.0594753e-03]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## NOTE: If you are using Safari and this cell throws an error,\n",
    "## please skip this block and run the next one instead.\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    " \n",
    "  # predicting images\n",
    "path=r'test\\Down-Wrong\\36_7_380 - Copy.jpg'\n",
    "img=load_img(path, target_size=(224, 224))\n",
    "  \n",
    "x=img_to_array(img)\n",
    "x /= 255\n",
    "x=np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "  \n",
    "classes = model.predict(images, batch_size=16)\n",
    "print(\"Down-Wrong\")  \n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9f3602e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "Up-Correct\n",
      "[6.8621034e-06 2.5139449e-04 9.9973899e-01 2.7283929e-06]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## NOTE: If you are using Safari and this cell throws an error,\n",
    "## please skip this block and run the next one instead.\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    " \n",
    "  # predicting images\n",
    "path=r'test\\Up-Correct\\73_2464_png.rf.2f909fcd964c70cb7497abf4e5501142.jpg'\n",
    "img=load_img(path, target_size=(224, 224))\n",
    "  \n",
    "x=img_to_array(img)\n",
    "x /= 255\n",
    "x=np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "  \n",
    "classes = model.predict(images, batch_size=16)\n",
    "print(\"Up-Correct\")   \n",
    "print(classes[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a64b4f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n",
      "Up-Wrong\n",
      "[1.0375864e-03 1.2643187e-02 4.4660796e-05 9.8627454e-01]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## NOTE: If you are using Safari and this cell throws an error,\n",
    "## please skip this block and run the next one instead.\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    " \n",
    "  # predicting images\n",
    "path=r'test\\Up-Wrong\\74_21_390.jpg'\n",
    "img=load_img(path, target_size=(224, 224))\n",
    "  \n",
    "x=img_to_array(img)\n",
    "x /= 255\n",
    "x=np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "  \n",
    "classes = model.predict(images, batch_size=16)\n",
    "print(\"Up-Wrong\")  \n",
    "print(classes[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ee893a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "Down-Wrong\n",
      "[[9.9980468e-01 4.1279913e-05 1.1689356e-04 3.7087546e-05]]\n"
     ]
    }
   ],
   "source": [
    "## NOTE: If you are using Safari and this cell throws an error,\n",
    "## please skip this block and run the next one instead.\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    " \n",
    "  # predicting images\n",
    "path=r'Others\\cat.jpeg'\n",
    "img=load_img(path, target_size=(224, 224))\n",
    "  \n",
    "x=img_to_array(img)\n",
    "x /= 255\n",
    "x=np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "  \n",
    "classes = model.predict(images, batch_size=16)\n",
    "print(\"Down-Wrong\")  \n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "795b9aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.applications import MobileNetV2\n",
    "# model.save('Capstone Project_WOAI_model.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41b8ec1f",
   "metadata": {},
   "source": [
    "Predict Baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "56df3217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the model\n",
    "# model = load_model(\"keras_model.h5\", compile=False)\n",
    "\n",
    "# # Load the labels\n",
    "# class_names = open(\"labels.txt\", \"r\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "006aeda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model  # TensorFlow is required for Keras to work\n",
    "# import cv2  # Install opencv-python\n",
    "# import numpy as np\n",
    "\n",
    "# # Disable scientific notation for clarity\n",
    "# np.set_printoptions(suppress=True)\n",
    "\n",
    "# path=r'test\\Down-Correct\\9_59_8_25881_png.rf.c9feedfd7b97964360230b5b58942527.jpg'\n",
    "# image=load_img(path, target_size=(224, 224))\n",
    "\n",
    "# image = np.asarray(image, dtype=np.float32).reshape(1, 224, 224, 3)\n",
    "\n",
    "# # Normalize the image array\n",
    "# image = (image / 127.5) - 1\n",
    "\n",
    "# # Predicts the model\n",
    "# prediction = model.predict(image)\n",
    "# index = np.argmax(prediction)\n",
    "# class_name = class_names[index]\n",
    "# confidence_score = prediction[0][index]\n",
    "\n",
    "# # Print prediction and confidence score\n",
    "# print(\"Class:\", class_name[2:], end=\"\")\n",
    "# print(\"Confidence Score:\", str(np.round(confidence_score * 100))[:-2], \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "51fdc369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model  # TensorFlow is required for Keras to work\n",
    "# import cv2  # Install opencv-python\n",
    "# import numpy as np\n",
    "\n",
    "# # Disable scientific notation for clarity\n",
    "# np.set_printoptions(suppress=True)\n",
    "\n",
    "# path=r'test\\Down-Wrong\\image2_432.jpg'\n",
    "# image=load_img(path, target_size=(224, 224))\n",
    "\n",
    "# image = np.asarray(image, dtype=np.float32).reshape(1, 224, 224, 3)\n",
    "\n",
    "# # Normalize the image array\n",
    "# image = (image / 127.5) - 1\n",
    "\n",
    "# # Predicts the model\n",
    "# prediction = model.predict(image)\n",
    "# index = np.argmax(prediction)\n",
    "# class_name = class_names[index]\n",
    "# confidence_score = prediction[0][index]\n",
    "\n",
    "# # Print prediction and confidence score\n",
    "# print(\"Class:\", class_name[2:], end=\"\")\n",
    "# print(\"Confidence Score:\", str(np.round(confidence_score * 100))[:-2], \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8ad66583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model  # TensorFlow is required for Keras to work\n",
    "# import cv2  # Install opencv-python\n",
    "# import numpy as np\n",
    "\n",
    "# # Disable scientific notation for clarity\n",
    "# np.set_printoptions(suppress=True)\n",
    "\n",
    "# path=r'test\\Up-Correct\\6068_png.rf.31490652a258e3f4f98e89015b326a31.jpg'\n",
    "# image=load_img(path, target_size=(224, 224))\n",
    "\n",
    "# image = np.asarray(image, dtype=np.float32).reshape(1, 224, 224, 3)\n",
    "\n",
    "# # Normalize the image array\n",
    "# image = (image / 127.5) - 1\n",
    "\n",
    "# # Predicts the model\n",
    "# prediction = model.predict(image)\n",
    "# index = np.argmax(prediction)\n",
    "# class_name = class_names[index]\n",
    "# confidence_score = prediction[0][index]\n",
    "\n",
    "# # Print prediction and confidence score\n",
    "# print(\"Class:\", class_name[2:], end=\"\")\n",
    "# print(\"Confidence Score:\", str(np.round(confidence_score * 100))[:-2], \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4185c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model  # TensorFlow is required for Keras to work\n",
    "# import cv2  # Install opencv-python\n",
    "# import numpy as np\n",
    "\n",
    "# # Disable scientific notation for clarity\n",
    "# np.set_printoptions(suppress=True)\n",
    "\n",
    "# path=r'test\\Up-Wrong\\image8_882.jpg'\n",
    "# image=load_img(path, target_size=(224, 224))\n",
    "\n",
    "# image = np.asarray(image, dtype=np.float32).reshape(1, 224, 224, 3)\n",
    "\n",
    "# # Normalize the image array\n",
    "# image = (image / 127.5) - 1\n",
    "\n",
    "# # Predicts the model\n",
    "# prediction = model.predict(image)\n",
    "# index = np.argmax(prediction)\n",
    "# class_name = class_names[index]\n",
    "# confidence_score = prediction[0][index]\n",
    "\n",
    "# # Print prediction and confidence score\n",
    "# print(\"Class:\", class_name[2:], end=\"\")\n",
    "# print(\"Confidence Score:\", str(np.round(confidence_score * 100))[:-2], \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e5f073f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\mohsu\\AppData\\Local\\Temp\\tmp1keor4ut\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\mohsu\\AppData\\Local\\Temp\\tmp1keor4ut\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully converted to TensorFlow Lite format: 15Desember2023-2.tflite\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the HDF5 model\n",
    "model_path = '15Desember2023-2.h5'\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Convert the model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model to a file\n",
    "tflite_path = '15Desember2023-2.tflite'\n",
    "with open(tflite_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f'Model successfully converted to TensorFlow Lite format: {tflite_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
